{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Restructuring OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def restructure(dir, num_classes):\n",
    "    for i in range(1, num_classes+1):\n",
    "        dir_to_create = f\".\\\\{dir}\\\\flower{str(i)}\"\n",
    "        \n",
    "        if not os.path.isdir(dir_to_create):\n",
    "            os.mkdir(dir_to_create)\n",
    "\n",
    "    cwd = os.path.abspath(dir)\n",
    "\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            os.replace(f\"{cwd}\\\\{file}\", f\"{cwd}\\\\flower{file.split(\"_\")[0]}\\\\{file}\")\n",
    "\n",
    "restructure(\"train_data\", 60)\n",
    "restructure(\"val_data\", 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Load Dataset into torch Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"train_data\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(\"val_data\", transform=transform)\n",
    "\n",
    "batch_size = 256\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=12288, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=60, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(64*64*3, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.30),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.30),\n",
    "            nn.Linear(512, 60),\n",
    "        \n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        logits = self.linear_relu_stack(X)\n",
    "        return logits\n",
    "    \n",
    "model = Model().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        one_hot_y = torch.eye(60)[y].to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, one_hot_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, current = loss.item(), batch * batch_size + len(X)\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            one_hot_y = torch.eye(60)[y].to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, one_hot_y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.119507  [  256/ 3000]\n",
      "loss: 4.540195  [  512/ 3000]\n",
      "loss: 4.339043  [  768/ 3000]\n",
      "loss: 4.466749  [ 1024/ 3000]\n",
      "loss: 4.059376  [ 1280/ 3000]\n",
      "loss: 3.930195  [ 1536/ 3000]\n",
      "loss: 4.096182  [ 1792/ 3000]\n",
      "loss: 3.757554  [ 2048/ 3000]\n",
      "loss: 3.707516  [ 2304/ 3000]\n",
      "loss: 3.523598  [ 2560/ 3000]\n",
      "loss: 3.552336  [ 2816/ 3000]\n",
      "loss: 3.559395  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 19.5%, Avg loss: 3.211671 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.156513  [  256/ 3000]\n",
      "loss: 3.179154  [  512/ 3000]\n",
      "loss: 3.140869  [  768/ 3000]\n",
      "loss: 3.092308  [ 1024/ 3000]\n",
      "loss: 2.728688  [ 1280/ 3000]\n",
      "loss: 2.967346  [ 1536/ 3000]\n",
      "loss: 3.178225  [ 1792/ 3000]\n",
      "loss: 2.835359  [ 2048/ 3000]\n",
      "loss: 3.070938  [ 2304/ 3000]\n",
      "loss: 3.010839  [ 2560/ 3000]\n",
      "loss: 2.802569  [ 2816/ 3000]\n",
      "loss: 2.984619  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 2.849934 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.710977  [  256/ 3000]\n",
      "loss: 2.515110  [  512/ 3000]\n",
      "loss: 2.383428  [  768/ 3000]\n",
      "loss: 2.523715  [ 1024/ 3000]\n",
      "loss: 2.510063  [ 1280/ 3000]\n",
      "loss: 2.529368  [ 1536/ 3000]\n",
      "loss: 2.407705  [ 1792/ 3000]\n",
      "loss: 2.455833  [ 2048/ 3000]\n",
      "loss: 2.521703  [ 2304/ 3000]\n",
      "loss: 2.354910  [ 2560/ 3000]\n",
      "loss: 2.575590  [ 2816/ 3000]\n",
      "loss: 2.554692  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 29.2%, Avg loss: 2.661523 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.024569  [  256/ 3000]\n",
      "loss: 2.195261  [  512/ 3000]\n",
      "loss: 2.056770  [  768/ 3000]\n",
      "loss: 2.137674  [ 1024/ 3000]\n",
      "loss: 2.037978  [ 1280/ 3000]\n",
      "loss: 2.188526  [ 1536/ 3000]\n",
      "loss: 2.152389  [ 1792/ 3000]\n",
      "loss: 2.065653  [ 2048/ 3000]\n",
      "loss: 2.324885  [ 2304/ 3000]\n",
      "loss: 2.193012  [ 2560/ 3000]\n",
      "loss: 1.909124  [ 2816/ 3000]\n",
      "loss: 2.198278  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 32.0%, Avg loss: 2.644437 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.857897  [  256/ 3000]\n",
      "loss: 1.746630  [  512/ 3000]\n",
      "loss: 1.794494  [  768/ 3000]\n",
      "loss: 1.687852  [ 1024/ 3000]\n",
      "loss: 1.666939  [ 1280/ 3000]\n",
      "loss: 1.726053  [ 1536/ 3000]\n",
      "loss: 1.619324  [ 1792/ 3000]\n",
      "loss: 1.845866  [ 2048/ 3000]\n",
      "loss: 1.739781  [ 2304/ 3000]\n",
      "loss: 2.120976  [ 2560/ 3000]\n",
      "loss: 1.801642  [ 2816/ 3000]\n",
      "loss: 1.888774  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 2.694188 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.554866  [  256/ 3000]\n",
      "loss: 1.466613  [  512/ 3000]\n",
      "loss: 1.439322  [  768/ 3000]\n",
      "loss: 1.500368  [ 1024/ 3000]\n",
      "loss: 1.567830  [ 1280/ 3000]\n",
      "loss: 1.529624  [ 1536/ 3000]\n",
      "loss: 1.702431  [ 1792/ 3000]\n",
      "loss: 1.402944  [ 2048/ 3000]\n",
      "loss: 1.558652  [ 2304/ 3000]\n",
      "loss: 1.644099  [ 2560/ 3000]\n",
      "loss: 1.542522  [ 2816/ 3000]\n",
      "loss: 1.564252  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 2.706845 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.200209  [  256/ 3000]\n",
      "loss: 1.371483  [  512/ 3000]\n",
      "loss: 1.380211  [  768/ 3000]\n",
      "loss: 1.321805  [ 1024/ 3000]\n",
      "loss: 1.366555  [ 1280/ 3000]\n",
      "loss: 1.139410  [ 1536/ 3000]\n",
      "loss: 1.140853  [ 1792/ 3000]\n",
      "loss: 1.232958  [ 2048/ 3000]\n",
      "loss: 1.271220  [ 2304/ 3000]\n",
      "loss: 1.254762  [ 2560/ 3000]\n",
      "loss: 1.220468  [ 2816/ 3000]\n",
      "loss: 1.427734  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 2.731927 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.111869  [  256/ 3000]\n",
      "loss: 1.041491  [  512/ 3000]\n",
      "loss: 1.160501  [  768/ 3000]\n",
      "loss: 1.150876  [ 1024/ 3000]\n",
      "loss: 1.170170  [ 1280/ 3000]\n",
      "loss: 1.127051  [ 1536/ 3000]\n",
      "loss: 1.200577  [ 1792/ 3000]\n",
      "loss: 0.995301  [ 2048/ 3000]\n",
      "loss: 1.197922  [ 2304/ 3000]\n",
      "loss: 1.113581  [ 2560/ 3000]\n",
      "loss: 1.009283  [ 2816/ 3000]\n",
      "loss: 1.215470  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.818868 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.987096  [  256/ 3000]\n",
      "loss: 0.934304  [  512/ 3000]\n",
      "loss: 0.774763  [  768/ 3000]\n",
      "loss: 1.008509  [ 1024/ 3000]\n",
      "loss: 0.979997  [ 1280/ 3000]\n",
      "loss: 0.899485  [ 1536/ 3000]\n",
      "loss: 0.859050  [ 1792/ 3000]\n",
      "loss: 0.825493  [ 2048/ 3000]\n",
      "loss: 1.128640  [ 2304/ 3000]\n",
      "loss: 0.921110  [ 2560/ 3000]\n",
      "loss: 0.877395  [ 2816/ 3000]\n",
      "loss: 0.962410  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 2.801277 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.649319  [  256/ 3000]\n",
      "loss: 0.778453  [  512/ 3000]\n",
      "loss: 0.725254  [  768/ 3000]\n",
      "loss: 0.712936  [ 1024/ 3000]\n",
      "loss: 0.694630  [ 1280/ 3000]\n",
      "loss: 0.937542  [ 1536/ 3000]\n",
      "loss: 0.750645  [ 1792/ 3000]\n",
      "loss: 0.808805  [ 2048/ 3000]\n",
      "loss: 0.809859  [ 2304/ 3000]\n",
      "loss: 0.872643  [ 2560/ 3000]\n",
      "loss: 0.779042  [ 2816/ 3000]\n",
      "loss: 0.800455  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.963165 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.741019  [  256/ 3000]\n",
      "loss: 0.596043  [  512/ 3000]\n",
      "loss: 0.579166  [  768/ 3000]\n",
      "loss: 0.748638  [ 1024/ 3000]\n",
      "loss: 0.601355  [ 1280/ 3000]\n",
      "loss: 0.634325  [ 1536/ 3000]\n",
      "loss: 0.673449  [ 1792/ 3000]\n",
      "loss: 0.569278  [ 2048/ 3000]\n",
      "loss: 0.562538  [ 2304/ 3000]\n",
      "loss: 0.773183  [ 2560/ 3000]\n",
      "loss: 0.743323  [ 2816/ 3000]\n",
      "loss: 0.676001  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 38.5%, Avg loss: 3.090472 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.602907  [  256/ 3000]\n",
      "loss: 0.555693  [  512/ 3000]\n",
      "loss: 0.525503  [  768/ 3000]\n",
      "loss: 0.556091  [ 1024/ 3000]\n",
      "loss: 0.632551  [ 1280/ 3000]\n",
      "loss: 0.726435  [ 1536/ 3000]\n",
      "loss: 0.584152  [ 1792/ 3000]\n",
      "loss: 0.556833  [ 2048/ 3000]\n",
      "loss: 0.667309  [ 2304/ 3000]\n",
      "loss: 0.543206  [ 2560/ 3000]\n",
      "loss: 0.643663  [ 2816/ 3000]\n",
      "loss: 0.712740  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 37.8%, Avg loss: 3.188614 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.450534  [  256/ 3000]\n",
      "loss: 0.446559  [  512/ 3000]\n",
      "loss: 0.519597  [  768/ 3000]\n",
      "loss: 0.482969  [ 1024/ 3000]\n",
      "loss: 0.646315  [ 1280/ 3000]\n",
      "loss: 0.442056  [ 1536/ 3000]\n",
      "loss: 0.524976  [ 1792/ 3000]\n",
      "loss: 0.536052  [ 2048/ 3000]\n",
      "loss: 0.532277  [ 2304/ 3000]\n",
      "loss: 0.531737  [ 2560/ 3000]\n",
      "loss: 0.591118  [ 2816/ 3000]\n",
      "loss: 0.592449  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 3.223787 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.419953  [  256/ 3000]\n",
      "loss: 0.393930  [  512/ 3000]\n",
      "loss: 0.462827  [  768/ 3000]\n",
      "loss: 0.422929  [ 1024/ 3000]\n",
      "loss: 0.370750  [ 1280/ 3000]\n",
      "loss: 0.383379  [ 1536/ 3000]\n",
      "loss: 0.506010  [ 1792/ 3000]\n",
      "loss: 0.477249  [ 2048/ 3000]\n",
      "loss: 0.517172  [ 2304/ 3000]\n",
      "loss: 0.468002  [ 2560/ 3000]\n",
      "loss: 0.492674  [ 2816/ 3000]\n",
      "loss: 0.510261  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 3.333129 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.416041  [  256/ 3000]\n",
      "loss: 0.363300  [  512/ 3000]\n",
      "loss: 0.378858  [  768/ 3000]\n",
      "loss: 0.441415  [ 1024/ 3000]\n",
      "loss: 0.426674  [ 1280/ 3000]\n",
      "loss: 0.416797  [ 1536/ 3000]\n",
      "loss: 0.458515  [ 1792/ 3000]\n",
      "loss: 0.394498  [ 2048/ 3000]\n",
      "loss: 0.489771  [ 2304/ 3000]\n",
      "loss: 0.376356  [ 2560/ 3000]\n",
      "loss: 0.442084  [ 2816/ 3000]\n",
      "loss: 0.523026  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 3.337271 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.278581  [  256/ 3000]\n",
      "loss: 0.367076  [  512/ 3000]\n",
      "loss: 0.383432  [  768/ 3000]\n",
      "loss: 0.372043  [ 1024/ 3000]\n",
      "loss: 0.389004  [ 1280/ 3000]\n",
      "loss: 0.400955  [ 1536/ 3000]\n",
      "loss: 0.374223  [ 1792/ 3000]\n",
      "loss: 0.380452  [ 2048/ 3000]\n",
      "loss: 0.393996  [ 2304/ 3000]\n",
      "loss: 0.389381  [ 2560/ 3000]\n",
      "loss: 0.399846  [ 2816/ 3000]\n",
      "loss: 0.405660  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 3.314608 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.286114  [  256/ 3000]\n",
      "loss: 0.262090  [  512/ 3000]\n",
      "loss: 0.378174  [  768/ 3000]\n",
      "loss: 0.438857  [ 1024/ 3000]\n",
      "loss: 0.345837  [ 1280/ 3000]\n",
      "loss: 0.467975  [ 1536/ 3000]\n",
      "loss: 0.309277  [ 1792/ 3000]\n",
      "loss: 0.400302  [ 2048/ 3000]\n",
      "loss: 0.415616  [ 2304/ 3000]\n",
      "loss: 0.485788  [ 2560/ 3000]\n",
      "loss: 0.347672  [ 2816/ 3000]\n",
      "loss: 0.356397  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 3.627867 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.268715  [  256/ 3000]\n",
      "loss: 0.278655  [  512/ 3000]\n",
      "loss: 0.270405  [  768/ 3000]\n",
      "loss: 0.266863  [ 1024/ 3000]\n",
      "loss: 0.310932  [ 1280/ 3000]\n",
      "loss: 0.421166  [ 1536/ 3000]\n",
      "loss: 0.369589  [ 1792/ 3000]\n",
      "loss: 0.302295  [ 2048/ 3000]\n",
      "loss: 0.336777  [ 2304/ 3000]\n",
      "loss: 0.283131  [ 2560/ 3000]\n",
      "loss: 0.490259  [ 2816/ 3000]\n",
      "loss: 0.364158  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 3.567245 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.198950  [  256/ 3000]\n",
      "loss: 0.282808  [  512/ 3000]\n",
      "loss: 0.358845  [  768/ 3000]\n",
      "loss: 0.288128  [ 1024/ 3000]\n",
      "loss: 0.476656  [ 1280/ 3000]\n",
      "loss: 0.324595  [ 1536/ 3000]\n",
      "loss: 0.293834  [ 1792/ 3000]\n",
      "loss: 0.205959  [ 2048/ 3000]\n",
      "loss: 0.369991  [ 2304/ 3000]\n",
      "loss: 0.401330  [ 2560/ 3000]\n",
      "loss: 0.365202  [ 2816/ 3000]\n",
      "loss: 0.242341  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 3.680737 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.281380  [  256/ 3000]\n",
      "loss: 0.260634  [  512/ 3000]\n",
      "loss: 0.268757  [  768/ 3000]\n",
      "loss: 0.271564  [ 1024/ 3000]\n",
      "loss: 0.214056  [ 1280/ 3000]\n",
      "loss: 0.234877  [ 1536/ 3000]\n",
      "loss: 0.275730  [ 1792/ 3000]\n",
      "loss: 0.296199  [ 2048/ 3000]\n",
      "loss: 0.385299  [ 2304/ 3000]\n",
      "loss: 0.363247  [ 2560/ 3000]\n",
      "loss: 0.219313  [ 2816/ 3000]\n",
      "loss: 0.198532  [ 3000/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 3.666629 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dl, model, loss_fn, optimizer)\n",
    "    test_loop(val_dl, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = dict([(b, a) for a, b in train_dataset.class_to_idx.items()])\n",
    "# for images, labels in train_dl:\n",
    "#     print(idx_to_class[labels[0].item()])\n",
    "#     imshow(images[0].permute(1, 2, 0))\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
